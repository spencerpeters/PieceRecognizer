{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import time as time\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from sklearn.feature_extraction.image import grid_to_graph\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.utils.testing import SkipTest\n",
    "from sklearn.utils.fixes import sp_version\n",
    "\n",
    "# compression of image width\n",
    "ZOOM_FACTOR = 25\n",
    "\n",
    "\n",
    "# input: image array and optional zoom factor z\n",
    "# output: compressed image array (by factor z^2)\n",
    "def comp(img,z = ZOOM_FACTOR):\n",
    "#     img=mpimg.imread(impath)\n",
    "    compress = img[0:len(img):z,0:len(img[0]):z]\n",
    "    return compress\n",
    "\n",
    "# converts image to greyscale by taking averages of rgb values\n",
    "# returns compressed image, compressed greyscale image\n",
    "def avg(img, compress = True, z = ZOOM_FACTOR):\n",
    "    if compress:\n",
    "        img = comp(img,z)\n",
    "    w = np.zeros((len(img),len(img[0])))\n",
    "    for i in range(len(img)):\n",
    "        for j in range(len(img[0])):\n",
    "            w[i][j] = int(img[i][j][0]/3.0+img[i][j][1]/3.0+img[i][j][2]/3.0)\n",
    "    return img, w\n",
    "\n",
    "\n",
    "# transforms a coordinate from compressed to full size image\n",
    "def c2f(x,z = ZOOM_FACTOR):\n",
    "    return int(z * x)\n",
    "\n",
    "\n",
    "# takes in an image array and optional number of clusters desired\n",
    "# returns array of size of image whose nonzero values are to which cluster each pixel belongs\n",
    "def cluster(impath, n = 15, compress = True, usefiltr = False): #usep will filter out small clusters\n",
    "                                                                          \n",
    "    full_img = impath\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 15))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    img, grey = avg(impath, compress)\n",
    "    axes[0].imshow(img)\n",
    "\n",
    "    # initializes connectivity matrix\n",
    "    connectivity = grid_to_graph(*grey.shape)\n",
    "\n",
    "    X = np.reshape(img, (-1, 3))\n",
    "    print(\"Compute structured hierarchical clustering...\")\n",
    "    st = time.time()\n",
    "    n_clusters = n  # number of regions\n",
    "\n",
    "    # linkage basically chooses how \"distance\" between color values computed, ward only setting that worked for me\n",
    "    ward = AgglomerativeClustering(n_clusters=n_clusters, linkage='ward',\n",
    "                                   connectivity=connectivity, compute_full_tree = 'auto')\n",
    "    ward.fit(X)\n",
    "    label = np.reshape(ward.labels_, grey.shape)\n",
    "    print(\"Elapsed time: \", time.time() - st)\n",
    "    print(\"Number of pixels: \", label.size)\n",
    "    print(\"Number of clusters: \", np.unique(label).size)\n",
    "    return label\n",
    "    \n",
    "# takes in an image array and a clustering label for that image\n",
    "# returns a list of areas, perimeters, average color, and standard deviation of color (as a tuple of type (area,\n",
    "# perimeter, color avg, color std deviation), perim/area)\n",
    "def get_cs(impath, label):\n",
    "    comp_img = comp(impath)\n",
    "    l = grey.shape[0]\n",
    "    w = grey.shape[1]\n",
    "    minp = label.size * MINP\n",
    "    maxp = label.size * MAXP\n",
    "    # counts how many pixels are in cluster l\n",
    "    count = np.zeros((n_clusters,1)\n",
    "    area = np.zeros((n_clusters,1))\n",
    "    # this is literally a list of all the values that are in cluster n, to make getting color statistics about it easier\n",
    "    list_colors = np.zeros((n_clusters, 1))\n",
    "    \n",
    "    # count perimeter of each cluster\n",
    "    # doesn't count last row/column but that should be okay?\n",
    "    for i in range(1,np.shape(label)[0]-1):\n",
    "        for j in range(1,np.shape(label)[1]-1):\n",
    "            area[label[i,j]] += 1\n",
    "            list_colors[label[i,j]].append(comp_img[i,j])\n",
    "            cl = label[i,j]\n",
    "            if (cl != label[i,j+1] or cl != label[i, j-1]) or (cl != label[i+1,j] or cl != label[i-1,j]):\n",
    "                count[label[i,j]] += 1\n",
    "    \n",
    "    R_avg = np.mean(list_colors, 1)\n",
    "    G_avg = np.mean(list_colors, 2)\n",
    "    B_avg = np.mean(list_colors, 3)\n",
    "    R_std = np.std(list_colors, 1)\n",
    "    G_std = np.std(list_colors, 2)\n",
    "    B_std = np.std(list_colors, 3)\n",
    "    return (area, count, (R_avg, G_avg, B_avg), (R_std, G_std, B_std), count/area)\n",
    "    \n",
    "# does the full processing on the image\n",
    "def process_image(impath):\n",
    "    label = cluster(impath)\n",
    "    stats = get_cs(impath, label)\n",
    "    return stats\n",
    "\n",
    "# takes a list of all the images to train on as well as the correct output for each image                \n",
    "def train_perceptron(list_of_img, correct_result):\n",
    "    for img in range(list_of_img):\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
